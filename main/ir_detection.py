import cv2
from math import *  #
import numpy as np

# threshold how much of a difference is accepted as a human
GREYSCALE_DIFFERENCE_THRESHOLD = 30

# an array where the mapping of the ir image blocks are saved
# for each block in the ir image, a corresponding tuple (x,y,w,h) is saved
# enumeration starts at the top left and is then counted line by line

# TODO: get the calibration data
calibration = [(600, 670, 35, 35), (600, 635, 35, 35), (600, 600, 35, 35), (600, 565, 35, 35), (600, 530, 35, 35), (600, 495, 35, 35), (600, 460, 35, 35), (600, 425, 35, 35), (600, 390, 35, 35), (600, 355, 35, 35), (600, 320, 35, 35), (600, 285, 35, 35), (600, 250, 35, 35), (600, 215, 35, 35), (600, 180, 35, 35), (600, 145, 35, 35), (600, 110, 35, 35), (600, 75, 35, 35), (600, 40, 35, 35), (635, 670, 35, 35), (635, 635, 35, 35), (635, 600, 35, 35), (635, 565, 35, 35), (635, 530, 35, 35), (635, 495, 35, 35), (635, 460, 35, 35), (635, 425, 35, 35), (635, 390, 35, 35), (635, 355, 35, 35), (635, 320, 35, 35), (635, 285, 35, 35), (635, 250, 35, 35), (635, 215, 35, 35), (635, 180, 35, 35), (635, 145, 35, 35), (635, 110, 35, 35), (635, 75, 35, 35), (635, 40, 35, 35), (670, 670, 35, 35), (670, 635, 35, 35), (670, 600, 35, 35), (670, 565, 35, 35), (670, 530, 35, 35), (670, 495, 35, 35), (670, 460, 35, 35), (670, 425, 35, 35), (670, 390, 35, 35), (670, 355, 35, 35), (670, 320, 35, 35), (670, 285, 35, 35), (670, 250, 35, 35), (670, 215, 35, 35), (670, 180, 35, 35), (670, 145, 35, 35), (670, 110, 35, 35), (670, 75, 35, 35), (670, 40, 35, 35), (705, 670, 35, 35), (705, 635, 35, 35), (705, 600, 35, 35), (705, 565, 35, 35), (705, 530, 35, 35), (705, 495, 35, 35), (705, 460, 35, 35), (705, 425, 35, 35), (705, 390, 35, 35), (705, 355, 35, 35), (705, 320, 35, 35), (705, 285, 35, 35), (705, 250, 35, 35), (705, 215, 35, 35), (705, 180, 35, 35), (705, 145, 35, 35), (705, 110, 35, 35), (705, 75, 35, 35), (705, 40, 35, 35), (740, 670, 35, 35), (740, 635, 35, 35), (740, 600, 35, 35), (740, 565, 35, 35), (740, 530, 35, 35), (740, 495, 35, 35), (740, 460, 35, 35), (740, 425, 35, 35), (740, 390, 35, 35), (740, 355, 35, 35), (740, 320, 35, 35), (740, 285, 35, 35), (740, 250, 35, 35), (740, 215, 35, 35), (740, 180, 35, 35), (740, 145, 35, 35), (740, 110, 35, 35), (740, 75, 35, 35), (740, 40, 35, 35), (775, 670, 35, 35), (775, 635, 35, 35), (775, 600, 35, 35), (775, 565, 35, 35), (775, 530, 35, 35), (775, 495, 35, 35), (775, 460, 35, 35), (775, 425, 35, 35), (775, 390, 35, 35), (775, 355, 35, 35), (775, 320, 35, 35), (775, 285, 35, 35), (775, 250, 35, 35), (775, 215, 35, 35), (775, 180, 35, 35), (775, 145, 35, 35), (775, 110, 35, 35), (775, 75, 35, 35), (775, 40, 35, 35), (810, 670, 35, 35), (810, 635, 35, 35), (810, 600, 35, 35), (810, 565, 35, 35), (810, 530, 35, 35), (810, 495, 35, 35), (810, 460, 35, 35), (810, 425, 35, 35), (810, 390, 35, 35), (810, 355, 35, 35), (810, 320, 35, 35), (810, 285, 35, 35), (810, 250, 35, 35), (810, 215, 35, 35), (810, 180, 35, 35), (810, 145, 35, 35), (810, 110, 35, 35), (810, 75, 35, 35), (810, 40, 35, 35), (845, 670, 35, 35), (845, 635, 35, 35), (845, 600, 35, 35), (845, 565, 35, 35), (845, 530, 35, 35), (845, 495, 35, 35), (845, 460, 35, 35), (845, 425, 35, 35), (845, 390, 35, 35), (845, 355, 35, 35), (845, 320, 35, 35), (845, 285, 35, 35), (845, 250, 35, 35), (845, 215, 35, 35), (845, 180, 35, 35), (845, 145, 35, 35), (845, 110, 35, 35), (845, 75, 35, 35), (845, 40, 35, 35), (880, 670, 35, 35), (880, 635, 35, 35), (880, 600, 35, 35), (880, 565, 35, 35), (880, 530, 35, 35), (880, 495, 35, 35), (880, 460, 35, 35), (880, 425, 35, 35), (880, 390, 35, 35), (880, 355, 35, 35), (880, 320, 35, 35), (880, 285, 35, 35), (880, 250, 35, 35), (880, 215, 35, 35), (880, 180, 35, 35), (880, 145, 35, 35), (880, 110, 35, 35), (880, 75, 35, 35), (880, 40, 35, 35), (915, 670, 35, 35), (915, 635, 35, 35), (915, 600, 35, 35), (915, 565, 35, 35), (915, 530, 35, 35), (915, 495, 35, 35), (915, 460, 35, 35), (915, 425, 35, 35), (915, 390, 35, 35), (915, 355, 35, 35), (915, 320, 35, 35), (915, 285, 35, 35), (915, 250, 35, 35), (915, 215, 35, 35), (915, 180, 35, 35), (915, 145, 35, 35), (915, 110, 35, 35), (915, 75, 35, 35), (915, 40, 35, 35), (950, 670, 35, 35), (950, 635, 35, 35), (950, 600, 35, 35), (950, 565, 35, 35), (950, 530, 35, 35), (950, 495, 35, 35), (950, 460, 35, 35), (950, 425, 35, 35), (950, 390, 35, 35), (950, 355, 35, 35), (950, 320, 35, 35), (950, 285, 35, 35), (950, 250, 35, 35), (950, 215, 35, 35), (950, 180, 35, 35), (950, 145, 35, 35), (950, 110, 35, 35), (950, 75, 35, 35), (950, 40, 35, 35), (985, 670, 35, 35), (985, 635, 35, 35), (985, 600, 35, 35), (985, 565, 35, 35), (985, 530, 35, 35), (985, 495, 35, 35), (985, 460, 35, 35), (985, 425, 35, 35), (985, 390, 35, 35), (985, 355, 35, 35), (985, 320, 35, 35), (985, 285, 35, 35), (985, 250, 35, 35), (985, 215, 35, 35), (985, 180, 35, 35), (985, 145, 35, 35), (985, 110, 35, 35), (985, 75, 35, 35), (985, 40, 35, 35), (1020, 670, 35, 35), (1020, 635, 35, 35), (1020, 600, 35, 35), (1020, 565, 35, 35), (1020, 530, 35, 35), (1020, 495, 35, 35), (1020, 460, 35, 35), (1020, 425, 35, 35), (1020, 390, 35, 35), (1020, 355, 35, 35), (1020, 320, 35, 35), (1020, 285, 35, 35), (1020, 250, 35, 35), (1020, 215, 35, 35), (1020, 180, 35, 35), (1020, 145, 35, 35), (1020, 110, 35, 35), (1020, 75, 35, 35), (1020, 40, 35, 35), (1055, 670, 35, 35), (1055, 635, 35, 35), (1055, 600, 35, 35), (1055, 565, 35, 35), (1055, 530, 35, 35), (1055, 495, 35, 35), (1055, 460, 35, 35), (1055, 425, 35, 35), (1055, 390, 35, 35), (1055, 355, 35, 35), (1055, 320, 35, 35), (1055, 285, 35, 35), (1055, 250, 35, 35), (1055, 215, 35, 35), (1055, 180, 35, 35), (1055, 145, 35, 35), (1055, 110, 35, 35), (1055, 75, 35, 35), (1055, 40, 35, 35)]


def create_boxes(ir_frame):
    # create boxes of 11x11 px and return an array of them
    box_side_length = 11
    boxes_list = []
    height = ir_frame.shape[0]
    original_width = ir_frame.shape[1]
    width = ceil(original_width / box_side_length) * box_side_length

    print('ir frame width:{} height:{}'.format(width, height))
    for index in range(ceil(original_width / box_side_length) * ceil(height / box_side_length)):
        y = int((index * box_side_length) / width) * box_side_length
        x = int((index * box_side_length)  % width)
        # this cuts out the boxes (as numpy arrays) and appends them to the result
        if x + box_side_length > original_width:
            if y + box_side_length > height:
                ir_frame_block = ir_frame[y:height, x:original_width]
                boxes_list.append(ir_frame_block)
            else:
                ir_frame_block = (ir_frame[y: (y + box_side_length), x:original_width])
                boxes_list.append(ir_frame_block)
        else:
            if y + box_side_length > height:
                ir_frame_block = (ir_frame[y:height, x: (x + box_side_length)])
                boxes_list.append(ir_frame_block)
            else:
                ir_frame_block = (ir_frame[y: (y + box_side_length), x: (x + box_side_length)])
                boxes_list.append(ir_frame_block)

        
    return boxes_list


def detect_humans(ir_frame):
    # this return the bounding box on the colored image of the boxes where people where detected on the ir image
    detected_blocks = []
    frame_as_boxes = create_boxes(ir_frame)
    average_pixel_value = np.average(ir_frame)
    for index in range(len(frame_as_boxes)):# check whether the average pixel value of the box is lower than the average pixel value of the whole image (also include the threshold)
        if (np.average(frame_as_boxes[index]) - GREYSCALE_DIFFERENCE_THRESHOLD) > average_pixel_value:
            detected_blocks.append(calibration[index])
    return detected_blocks
